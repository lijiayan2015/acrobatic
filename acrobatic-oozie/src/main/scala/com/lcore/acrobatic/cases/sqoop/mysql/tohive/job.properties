
nameNode=hdfs://vhost1:9000
jobTracker=vhost1
queueName=default
oozie.use.system.libpath=true

oozie.wf.application.path=${nameNode}/oozie/apps/sqoop/tohive


#    直接使用sqoop从mysql导数据导hive表
#
#    sqoop import \
#    --connect jdbc:mysql://vhost1:3306/yss \
#    --table workers \
#    --username root \
#    --password root \
#    --fields-terminated-by ',' \
#    --delete-target-dir \
#    --hive-import \
#    --hive-database dbtest \
#    --hive-table workers \
#    --num-mappers 1
#
#    18/10/11 13:55:42 ERROR tool.ImportTool: Import failed: java.io.IOException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf
#    at org.apache.sqoop.hive.HiveConfig.getHiveConf(HiveConfig.java:50)
#    at org.apache.sqoop.hive.HiveImport.getHiveArgs(HiveImport.java:392)
#    at org.apache.sqoop.hive.HiveImport.executeExternalHiveScript(HiveImport.java:379)
#    at org.apache.sqoop.hive.HiveImport.executeScript(HiveImport.java:337)
#    at org.apache.sqoop.hive.HiveImport.importTable(HiveImport.java:241)
#    at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:537)
#    at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:628)
#    at org.apache.sqoop.Sqoop.run(Sqoop.java:147)
#    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
#    at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183)
#    at org.apache.sqoop.Sqoop.runTool(Sqoop.java:234)
#    at org.apache.sqoop.Sqoop.runTool(Sqoop.java:243)
#    at org.apache.sqoop.Sqoop.main(Sqoop.java:252)
#    Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf
#    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
#    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
#    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
#    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
#    at java.lang.Class.forName0(Native Method)
#    at java.lang.Class.forName(Class.java:264)
#    at org.apache.sqoop.hive.HiveConfig.getHiveConf(HiveConfig.java:44)
#    ... 12 more
#
#
#
#    Exception in thread "main" java.lang.NoClassDefFoundError: org/apache/hadoop/hive/shims/ShimLoader
#    at org.apache.hadoop.hive.conf.HiveConf$ConfVars.<clinit>(HiveConf.java:371)
#    at org.apache.hadoop.hive.conf.HiveConf.<clinit>(HiveConf.java:108)
#    at java.lang.Class.forName0(Native Method)
#    at java.lang.Class.forName(Class.java:264)
#    at org.apache.sqoop.hive.HiveConfig.getHiveConf(HiveConfig.java:44)
#    at org.apache.sqoop.hive.HiveImport.getHiveArgs(HiveImport.java:392)
#    at org.apache.sqoop.hive.HiveImport.executeExternalHiveScript(HiveImport.java:379)
#    at org.apache.sqoop.hive.HiveImport.executeScript(HiveImport.java:337)
#    at org.apache.sqoop.hive.HiveImport.importTable(HiveImport.java:241)
#    at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:537)
#    at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:628)
#    at org.apache.sqoop.Sqoop.run(Sqoop.java:147)
#    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
#    at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183)
#    at org.apache.sqoop.Sqoop.runTool(Sqoop.java:234)
#    at org.apache.sqoop.Sqoop.runTool(Sqoop.java:243)
#    at org.apache.sqoop.Sqoop.main(Sqoop.java:252)
#    Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.shims.ShimLoader
#    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
#    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
#    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
#    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
#    ... 17 more
#
#    以上两个错误是由于sqoop少了hive的jar包，将hive的lib下面的jar包拷贝到sqoop的lib下面即可
#
#
#
#       报hive数据库不存在：
#    sqoop中读取不到hive的配置文件hive-site.xml，将hive的conf下的hive-site.xml拷贝到sqoop的conf目录下即可解决。


# oozie 导数据：
# FAILED: SemanticException [Error 10072]: Database does not exist: dbtest
# 解决方案：1.在hive的hive-site.xml配置文件Configuration节点开始地方配置：
#                <property>
#                    <name>hive.metastore.uris</name>
#                    <value>thrift://vhost1:9083</value>
#                </property>
#         2.开启hive的service服务：nohup hive --service metastore &
#
#         3.在workflow的<configuration>配置节点下也添加：
#                <property>
#                    <name>hive.metastore.uris</name>
#                    <value>thrift://vhost1:9083</value>
#                </property>